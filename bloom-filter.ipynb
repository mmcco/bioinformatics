{
 "metadata": {
  "name": "",
  "signature": "sha256:7d9d545b4d6567e32cf9242163c466159b0ddab4b71d435b4675bebaf265f1be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you probably know, disk access is painfully slow and should be avoided at all costs. Often, programs use a large set, a group of unique values, that cannot fit in RAM and must be stored on disk. In a simple set implementation, we must access the full set data in order to add a value (regardless of whether it's already a member) and to check whether a value is a member.\n",
      "\n",
      "In many cases, it would be useful to have a smaller data structure stored in memory that estimates whether a value is a member of our set. Because this structure would be much smaller than the full set, thereby storing much less information, it could not give a definitive answer. However, instead of returning \u201cTrue\u201d or \u201cFalse\u201d when asked if a set contains a value, our \u201cfirst-pass filter\u201d could return \u201cPossibly\u201d or \u201cFalse\u201d. When it returns \u201cPossibly\u201d, the full set must then be searched to determine whether the value is actually a member. When it returns \u201cFalse\u201d, though, we need not access disk.\n",
      "\n",
      "A simple solution would be storing each value\u2019s [hash](https://en.wikipedia.org/wiki/Hash_function) in a list. Hash functions are many-to-one; multiple values can have the same hash, but each value has only one valid hash. If a value\u2019s hash exists in our list, the value might be in the set, or the set might just contain another value with the same hash (two values having the same hash is known as a *collision*). If the value\u2019s hash isn\u2019t in the list, the value definitely isn\u2019t in the set.\n",
      "\n",
      "A simply Python implementation of this filter is below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ListFilter:\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.hashes = []\n",
      "        \n",
      "        \n",
      "    def add(self, val):\n",
      "        valHash = hash(val)\n",
      "        if valHash not in self.hashes:\n",
      "            self.hashes.insert(valHash)\n",
      "            \n",
      "            \n",
      "    def check(self, val):\n",
      "        return hash(val) in self.hashes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`True` returned from `check` implies \"Probably\" because the filter can't definitively tell us whether a value is in the actual set.\n",
      "\n",
      "For simplicity and modularity, we didn't incorporate the actual set into the filter. This means that, after adding a value to the filter with `add`, a program would have to also add the value to the set. Similarly, if a program calls `check` and `True` is returned, it will have to check the set to see if the value is actually a member.\n",
      "\n",
      "Our first-pass list filter is a decent solution, but it isn\u2019t quite ideal. Ignoring collisions, it grows in proportion to the set, and therefore becomes unwieldy for really big sets. Assuming we don\u2019t want to use extra memory to make a hash table of the hashes, finding a hash is $O(\\log_2{n})$ if the list is sorted and $O(n)$ if it isn\u2019t.\n",
      "\n",
      "Bloom filters, an alternative, offer constant space and $O(1)$ checking. While the rate of *false positives* (\u201cProbably\u201d responses for values not in the set) increases modestly as the set grows, relatively small Bloom filters have low ($\\leq1\\%$) false positive rates for huge data sets.\n",
      "\n",
      "Below is an implementation of a Bloom filter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BloomFilter:\n",
      "\n",
      "    def __init__(self, m, k):\n",
      "        self.m = m\n",
      "        self.k = k\n",
      "        self.bitArray = [0 for _ in range(m)]\n",
      "\n",
      "        \n",
      "    def getIndices(self, val):\n",
      "        indices = []\n",
      "        for i in range(self.k):\n",
      "            hash_ = hash(str(i) + val)\n",
      "            index = hash_ % self.m\n",
      "            indices.append(index)\n",
      "        return indices\n",
      "\n",
      "    \n",
      "    def add(self, val):\n",
      "        indices = self.getIndices(val)\n",
      "        for index in indices:\n",
      "            self.bitArray[index] = 1\n",
      "\n",
      "            \n",
      "    def check(self, val):\n",
      "        indices = self.getIndices(val)\n",
      "        for index in indices:\n",
      "            if self.bitArray[index] == 0:\n",
      "                return False\n",
      "        return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A Bloom filter is stores an array of $m$ bits (`bitArray`, in our code), all of which are initially set to $0$. We use an integer list here for clarity. In a real implementation, each array index is only one bit. For readability, our below examples will use $m=16$. Typical real-world bloom filters use an $m$ value about $9.6$ times larger than the the expected number of elements in the set. This gives a false positive rate of about $1\\%$.\n",
      "\n",
      "The filter uses $k$ different hash functions. Often, these are just the same hash function with a different *salt*, a value prepended to the value to be hashed. In our implementation, the first hash function prepends `\"0\"`, the second prepends `\"1\"`, and so on. The hashing algorithm used is Python's default: `hash`.\n",
      "\n",
      "Each hash function\u2019s output must map to an index of the bit array. One way to do this is to ensure that the function\u2019s output is $\\log_2 m$ bits, mapping each hash value directly to an index of the bit array. If no available hash functions have our desired output size, we can use $hash \\bmod{m}$ to map the hash value to an array index:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hash(\"0\" + \"hopkins\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "4028870035670873848"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter = BloomFilter(m = 16, k = 3)\n",
      "print hash(\"0\" + \"hopkins\") % filter.m\n",
      "print hash(\"1\" + \"hopkins\") % filter.m\n",
      "print hash(\"2\" + \"hopkins\") % filter.m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8\n",
        "15\n",
        "6\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `getIndices` method, which does the hashing in our implementation, uses the $\\bmod$ solution. It returns a list of $k$ indices, each generated by a salted hash function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.getIndices(\"hopkins\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[8, 15, 6]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When a value is added to a Bloom filter, the bit array index indicated by each hash value is set to $1$. Our code uses the `add` method, calling `getIndices` and updating `bitArray` accordingly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.getIndices(\"hopkins\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[8, 15, 6]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.bitArray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.add(\"hopkins\")\n",
      "filter.bitArray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To check if a value is possibly in the Bloom filter's set, we compute its indices using `getIndices`. If the bit array values at any of these indices are $0$, then the value cannot be in the set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for index in filter.getIndices(\"johns\"):\n",
      "    print filter.bitArray[index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "0\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.check(\"johns\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The possibility of a false positive remains (especially with an $m$ value as unrealistically small as $16$):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.getIndices(\"bootstrap\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[8, 15, 6]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter.check(\"bootstrap\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using simple probability laws, we can estimate the probability of a false positive. We will assume that the hashing algorithm used is effectively random, which implies that the probability of a given $0$ bit being flipped to $1$ during a single bit assignment is $\\frac{1}{m}$. The probability of this bit remaining $0$ for a single index assignment is therefore $1 - \\frac{1}{m}$. By exponential decay, the probability that it will remain $0$ when a new value is added to the filter is:\n",
      "\n",
      "$(1 - \\frac{1}{m})^k$.\n",
      "\n",
      "Again by exponential decay, the probability that it will remain $0$ after $n$ values are added is:\n",
      "\n",
      "$((1 - \\frac{1}{m})^k)^n = (1 - \\frac{1}{m})^{kn}$\n",
      "\n",
      "This implies that the probability of a bit being $1$ after $n$ values are added to the filter is:\n",
      "\n",
      "$1 - (1 - \\frac{1}{m})^{kn}$\n",
      "\n",
      "For a false positive, all $k$ of a value's bit array indices must already be $1$ by chance. The probability of a false positive is therefore:\n",
      "\n",
      "$(1 - (1 - \\frac{1}{m})^{kn})^k$\n",
      "\n",
      "If we use five hash functions ($k=5$) and two gigabytes of RAM ($m=1.6 \\times 10^{10}$) for a Bloom filter and store a billion values in the set ($n=10^9$), the likelihood of a false positive is only:\n",
      "\n",
      "$(1 - (1 - \\frac{1}{m})^{kn})^k = (1 - (1 - \\frac{1}{1.6 \\times 10^10}) ^{5 \\times 10^9}) ^5 \\approx 0.0014 = 0.14\\%$\n",
      "\n",
      "It's clear why Bloom filters are used for massive-scale database software like Google BigTable, Apache Hadoop, and Apache Cassandra.\n",
      "\n",
      "---\n",
      "\n",
      "There are situations in which we can further improve our filter's performance. We may, for example, load a set of $k$-character-long strings into a Bloom filter and then search for these substrings in a larger string. Similarly, we may want to find if and where a genome sequence read differs from a reference genome. We could do this by storing all the reference genome's *$k$-mers* (sequences that are $k$ nucleotides long) in a set and checking which $k$-mers in the sequencing reads don't exist in the reference genome.\n",
      "\n",
      "These problems are best treated with frame shifting; to search for 4-long substrings in the string `\"refrigerator\"`, you would check `\"refr\"`, then `\"efri\"`, then `\"frig\"`, and so on. No matter the value of $k$, each substring differs from the one before it by only a deletion at the front and an insertion at the back. They are very similar, yet our current Bloom filter implementation doesn't reuse any computation when calculating their hashes.\n",
      "\n",
      "A family of hash functions known as *rolling hashes* exist for this purpose. They can convert a substring's hash to that of its successor frame, such as `hash(\"refr\")` to `hash(\"efri\")`, in $O(1)$ time. We will use the rolling hash function traditionally associated with the [Rabin\u2013Karp algorithm](https://en.wikipedia.org/wiki/Rabin-Karp_algorithm), an efficient method of searching for substrings. The hash value of a string of length $m$ is:\n",
      "\n",
      "$\\sum_{i=m-1}^{0} a_i \\times b^i$\n",
      "\n",
      "where $b$ is an arbitrary constant (typically prime) and $a_i$ is the ASCII value of the $i$th character of the string $a$. For example, the hash value of the string \"deck\" where $b=73$ (relevant ASCII values: $d=100$, $e=101$, $c=99$, $k=107$) is:\n",
      "\n",
      "$(100 \\times 73^3) + (101 \\times 73^2) + (99 \\times 73^1) + (107 \\times 73^0) = 39,447,263$\n",
      "\n",
      "A Python implementation is below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RKHash:\n",
      "    \n",
      "    def __init__(self, b):\n",
      "        self.b = b\n",
      "        self.prevFrame = None\n",
      "        self.prevHash = None\n",
      "        \n",
      "        \n",
      "    def getHash(self, frame):\n",
      "    \n",
      "        m = len(frame)\n",
      "    \n",
      "        if self.prevFrame and self.prevHash:\n",
      "            tailHash = self.prevHash - (ord(self.prevFrame[0]) * self.b ** (m-1))\n",
      "            thisHash = (tailHash * self.b) + ord(frame[-1])\n",
      "            \n",
      "        else:\n",
      "            thisHash = 0\n",
      "            for i in range(m):\n",
      "                thisHash += ord(frame[i]) * (self.b ** (m - (i + 1)))\n",
      "                \n",
      "        self.prevFrame = frame\n",
      "        self.prevHash = thisHash\n",
      "        return thisHash\n",
      "    \n",
      "    \n",
      "    def clear(self):\n",
      "        self.prevFrame = None\n",
      "        self.prevHash = None\n",
      "    \n",
      "    \n",
      "hasher = RKHash(6)\n",
      "firstHash = hasher.getHash(\"tomat\")\n",
      "print firstHash\n",
      "nextHash = hasher.getHash(\"omato\")\n",
      "print nextHash"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "178934\n",
        "171699\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logically, `prevFrame` and `prevHash` are initialized to `None`, and the first frame's hash value is computed from scratch. This is executed by the `else` clause in `getHash`, which simply computes the summation equation given above.\n",
      "\n",
      "The `if` clause is executed for all but the first frame. It converts `prevHash`, the previous frame's hash, to `thisHash`, the current frame's hash, in three simple $O(1)$ operations. We will observe these operations with an example `prevFrame` of length $4$, composed of characters $a_0$ through $a_3$. The algorithm converts its hash to that of its successor, `frame`, which is comprised of characters $a_1$ through $a_4$. Initially:\n",
      "\n",
      "$prevHash = (a_0 \\times b^3) + (a_1 \\times b^2) + (a_2 \\times b^1) + (a_3 \\times b^0)$\n",
      "\n",
      "We then subtract $a_0 \\times b^3$, obtaining the hash of `prevHash`'s tail (tail refers to all but the first character; the tail of `\"couch\"` is `\"ouch\"`):\n",
      "\n",
      "$(a_1 \\times b^2) + (a_2 \\times b^1) + (a_3 \\times b^0)$\n",
      "\n",
      "We then multiply by $b$:\n",
      "\n",
      "$(a_1 \\times b^3) + (a_2 \\times b^2) + (a_3 \\times b^1)$\n",
      "\n",
      "And add $a_4 \\times b^0 = a_4$ obtaining `thisHash`:\n",
      "\n",
      "$(a_1 \\times b^3) + (a_2 \\times b^2) + (a_3 \\times b^1) + (a_4 \\times b^0) = thisHash$\n",
      "\n",
      "Regardless of the length of the substrings processed, the algorithm uses only these three $O(1)$ arithmetic operations.\n",
      "\n",
      "The `clear` function simply resets the `RKHasher` instance, allowing us to start with a new first frame.\n",
      "\n",
      "We omitted exception statements checking soundness and sanity, so remember that `getHash` assumes that `len(frame) == len(prevFrame)`, that `prevFrame[1:] == frame[:-1]`, and that `b != 0`.\n",
      "\n",
      "Below is a modified version of our above Bloom filter implementation that uses Rabin-Karp hash functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "class BloomFilter:\n",
      "\n",
      "    def __init__(self, m, k):\n",
      "        self.m = m\n",
      "        self.k = k\n",
      "        self.bitArray = [0 for _ in range(m)]\n",
      "        \n",
      "        # random.sample(population, x) a list of x unique\n",
      "        # elements from the supplied population list\n",
      "        randBs = random.sample(range(1, 200), k)\n",
      "        self.hashFuncs = [RKHash(b) for b in randBs]\n",
      "        \n",
      "\n",
      "    def getIndices(self, val):\n",
      "        hashes = [f.getHash(val) for f in self.hashFuncs]\n",
      "        return map((lambda hash_: hash_ % self.m), hashes)\n",
      "            \n",
      "    \n",
      "    def add(self, val):\n",
      "        indices = self.getIndices(val)\n",
      "        for index in indices:\n",
      "            self.bitArray[index] = 1\n",
      "\n",
      "            \n",
      "    def check(self, val):\n",
      "        indices = self.getIndices(val)\n",
      "        for index in indices:\n",
      "            if self.bitArray[index] == 0:\n",
      "                return False\n",
      "        return True\n",
      "    \n",
      "bloomFilter = BloomFilter(1024, 3)\n",
      "print \"randomly selected b's for Rabin-Karp hash functions:\", [f.b for f in bloomFilter.hashFuncs]\n",
      "print \"indices returned for the string \\\"johns\\\":\", bloomFilter.getIndices(\"johns\")\n",
      "bloomFilter.add(\"johns\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "randomly selected b's for Rabin-Karp hash functions: [101, 3, 145]\n",
        "indices returned for the string \"johns\": [478, 676, 978]\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The value of $b$ for each Rabin-Karp hashing algorithm is unique and pseudorandomly selected. Higher values of $b$ more heavily weight earlier characters relative to later ones, so two values that collide in one hash function<!-- ($hash_x(a) = hash_x(b)$)--> are unlikely to collide in any other<!-- ($hash_y(a) = hash_y(b)$)-->:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hasher6 = RKHash(6)\n",
      "hasher7 = RKHash(7)\n",
      "\n",
      "print 'hasher6.getHash(\"kudos\") =', hasher6.getHash(\"kudos\")\n",
      "hasher6.clear()\n",
      "print 'hasher6.getHash(\"locus\") =', hasher6.getHash(\"locus\")\n",
      "print 'hasher7.getHash(\"kudos\") =', hasher7.getHash(\"kudos\")\n",
      "hasher7.clear()\n",
      "print 'hasher7.getHash(\"locus\") =', hasher7.getHash(\"locus\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hasher6.getHash(\"kudos\") = 168325\n",
        "hasher6.getHash(\"locus\") = 168325\n",
        "hasher7.getHash(\"kudos\") = 302830\n",
        "hasher7.getHash(\"locus\") = 303166\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
